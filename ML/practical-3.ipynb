{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a bank customer, build a neural network-based classifier that can determine whether \n",
    "they will leave or not in the next 6 months.\n",
    "Dataset Description: The case study is from an open-source dataset from Kaggle.\n",
    "The dataset contains 10,000 sample points with 14 distinct features such as\n",
    "CustomerId, CreditScore, Geography, Gender, Age, Tenure, Balance, etc.\n",
    "Link to the Kaggle project:\n",
    "https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
    "Perform following steps:\n",
    "1. Read the dataset.\n",
    "2. Distinguish the feature and target set and divide the data set into training and test sets.\n",
    "3. Normalize the train and test data. \n",
    "4. Initialize and build the model. Identify the points of improvement and implement the same. \n",
    "5. Print the accuracy score and confusion matrix (5 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/lokeshkhabiya/FourthYearStuff/practicals/lp-3/ML/Dataset/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Exited', 'CustomerId', 'Surname', 'RowNumber'])  # Exclude columns\n",
    "y = data['Exited']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
      "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
      "       'Exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Data Preprocessing\n",
    "# Handle missing values and encode categorical variables\n",
    "\n",
    "# Removing rows with missing values:\n",
    "data = data.drop(['CustomerId', 'Surname', 'RowNumber'], axis = 1)\n",
    "print(data.columns)\n",
    "\n",
    "# Replacing missing values with a specific value (e.g., mean):\n",
    "# data['column_name'].fillna(data['column_name'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to ensure that the columns 'Geography' and 'Gender' are present in the DataFrame X\n",
    "# Add additional error handling to verify the column names\n",
    "columns_to_encode = ['Geography', 'Gender']\n",
    "for column in columns_to_encode:\n",
    "    if column not in X.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in the DataFrame X.\")\n",
    "\n",
    "# You need to encode categorical variables like \"Geography\" and \"Gender\" into numerical format using one-hot encoding.\n",
    "X = pd.get_dummies(X, columns=['Geography', 'Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Initialize and Build the Model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 01:05:36.691518: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 399us/step - loss: 0.4828 - accuracy: 0.7947\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 0s 377us/step - loss: 0.4455 - accuracy: 0.8069\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 0s 366us/step - loss: 0.4211 - accuracy: 0.8173\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 0s 365us/step - loss: 0.3981 - accuracy: 0.8311\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 0s 368us/step - loss: 0.3753 - accuracy: 0.8439\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 0s 366us/step - loss: 0.3624 - accuracy: 0.8479\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 0s 366us/step - loss: 0.3576 - accuracy: 0.8506\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 0s 363us/step - loss: 0.3535 - accuracy: 0.8554\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 0s 364us/step - loss: 0.3509 - accuracy: 0.8545\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 0s 365us/step - loss: 0.3486 - accuracy: 0.8546\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 0s 367us/step - loss: 0.3466 - accuracy: 0.8545\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 0s 365us/step - loss: 0.3471 - accuracy: 0.8587\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 0s 376us/step - loss: 0.3447 - accuracy: 0.8566\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 0s 882us/step - loss: 0.3431 - accuracy: 0.8566\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 0s 871us/step - loss: 0.3423 - accuracy: 0.8589\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 0s 489us/step - loss: 0.3407 - accuracy: 0.8574\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.3400 - accuracy: 0.8571\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 0s 470us/step - loss: 0.3398 - accuracy: 0.8570\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 0s 434us/step - loss: 0.3380 - accuracy: 0.8614\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 0s 415us/step - loss: 0.3379 - accuracy: 0.8616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c13ef50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 322us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Convert to binary prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8615\n",
      "Confusion Matrix:\n",
      "[[1541   66]\n",
      " [ 211  182]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
